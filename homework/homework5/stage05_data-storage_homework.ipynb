{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 05 — Data Storage - Homework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR: /Users/aman/Desktop/Bootcamp/bootcamp_aman_dhillon/homework/homework5/data/raw\n",
      "PROC_DIR: /Users/aman/Desktop/Bootcamp/bootcamp_aman_dhillon/homework/homework5/data/processed\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, datetime as dt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import fastparquet\n",
    "\n",
    "load_dotenv()\n",
    "RAW_DIR = pathlib.Path(os.getenv(\"DATA_DIR_RAW\", \"data/raw\"))\n",
    "PROC_DIR = pathlib.Path(os.getenv(\"DATA_DIR_PROCESSED\", \"data/processed\"))\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"RAW_DIR:\", RAW_DIR.resolve())\n",
    "print(\"PROC_DIR:\", PROC_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sample DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    40 non-null     datetime64[ns]\n",
      " 1   ticker  40 non-null     object        \n",
      " 2   price   40 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dates = pd.date_range(\"2024-01-01\", periods=40, freq=\"D\")\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'ticker': ['TSLA']*40,\n",
    "    'price': 150 + np.random.randn(40).cumsum()\n",
    "})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV (raw) and Parquet (processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV → data/raw/prices_20250819-210841.csv\n",
      "Saved Parquet → data/processed/prices_20250819-210841.parquet\n"
     ]
    }
   ],
   "source": [
    "def ts():\n",
    "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "# Save CSV\n",
    "csv_path = RAW_DIR / f\"prices_{ts()}.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"Saved CSV →\", csv_path)\n",
    "\n",
    "# Save Parquet\n",
    "parq_path = PROC_DIR / f\"prices_{ts()}.parquet\"\n",
    "try:\n",
    "    df.to_parquet(parq_path, engine=\"fastparquet\")  # explicitly use pyarrow\n",
    "    print(\"Saved Parquet →\", parq_path)\n",
    "except Exception as e:\n",
    "    print(\"Parquet save failed (engine missing?). Skipping Parquet demo.\")\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV validation: {'shape_equal': True, 'cols_present': True, 'price_is_numeric': True, 'date_is_datetime': True}\n",
      "Parquet validation: {'shape_equal': True, 'cols_present': True, 'price_is_numeric': True, 'date_is_datetime': True}\n"
     ]
    }
   ],
   "source": [
    "def validate_loaded(original: pd.DataFrame, reloaded: pd.DataFrame, cols=('date','ticker','price')):\n",
    "    checks = {\n",
    "        'shape_equal': original.shape == reloaded.shape,\n",
    "        'cols_present': all(c in reloaded.columns for c in cols)\n",
    "    }\n",
    "    # dtype sanity checks\n",
    "    if 'price' in reloaded.columns:\n",
    "        checks['price_is_numeric'] = pd.api.types.is_numeric_dtype(reloaded['price'])\n",
    "    if 'date' in reloaded.columns:\n",
    "        checks['date_is_datetime'] = pd.api.types.is_datetime64_any_dtype(reloaded['date'])\n",
    "    return checks\n",
    "\n",
    "df_csv = pd.read_csv(csv_path, parse_dates=['date'])\n",
    "print('CSV validation:', validate_loaded(df, df_csv))\n",
    "\n",
    "if parq_path.exists():\n",
    "    try:\n",
    "        df_parq = pd.read_parquet(parq_path)\n",
    "        print('Parquet validation:', validate_loaded(df, df_parq))\n",
    "    except Exception as e:\n",
    "        print('Parquet read failed:', e)\n",
    "else:\n",
    "    print('Parquet file not present (skipped earlier).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO Utilities (suffix-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded CSV via util, shape: (40, 3)\n",
      "Reloaded Parquet via util, shape: (40, 3)\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "def ensure_dir(path: pathlib.Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def detect_format(path: Union[str, pathlib.Path]):\n",
    "    suf = str(path).lower()\n",
    "    if suf.endswith('.csv'): return 'csv'\n",
    "    if suf.endswith('.parquet') or suf.endswith('.pq') or suf.endswith('.parq'): return 'parquet'\n",
    "    raise ValueError('Unsupported format for: ' + str(path))\n",
    "\n",
    "def write_df(df: pd.DataFrame, path: Union[str, pathlib.Path]):\n",
    "    path = pathlib.Path(path)\n",
    "    ensure_dir(path)\n",
    "    fmt = detect_format(path)\n",
    "    if fmt == 'csv':\n",
    "        df.to_csv(path, index=False)\n",
    "    elif fmt == 'parquet':\n",
    "        try:\n",
    "            df.to_parquet(path,engine=\"fastparquet\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "    return path\n",
    "\n",
    "def read_df(path: Union[str, pathlib.Path]):\n",
    "    path = pathlib.Path(path)\n",
    "    fmt = detect_format(path)\n",
    "    if fmt == 'csv':\n",
    "        return pd.read_csv(path, parse_dates=['date']) if 'date' in pd.read_csv(path, nrows=0).columns else pd.read_csv(path)\n",
    "    elif fmt == 'parquet':\n",
    "        try:\n",
    "            return pd.read_parquet(path,engine=\"fastparquet\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "\n",
    "# Demo utility usage\n",
    "csv2 = RAW_DIR / f\"prices_util_{ts()}.csv\"\n",
    "pq2  = PROC_DIR / f\"prices_util_{ts()}.parquet\"\n",
    "write_df(df, csv2)\n",
    "df2 = read_df(csv2)\n",
    "print('Reloaded CSV via util, shape:', df2.shape)\n",
    "\n",
    "try:\n",
    "    write_df(df, pq2)\n",
    "    df3 = read_df(pq2)\n",
    "    print('Reloaded Parquet via util, shape:', df3.shape)\n",
    "except RuntimeError as e:\n",
    "    print('Parquet util demo skipped:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
